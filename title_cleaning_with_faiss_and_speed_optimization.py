# -*- coding: utf-8 -*-
"""Title_Cleaning_with_Faiss_and_Speed_Optimization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TI21KfecsfgMiE0ZeavkogETlX12txrl
"""

! pip install faiss-cpu
 ! pip install sentence-transformers

"""# Cleaning the titles of a csv file"""

from sentence_transformers import SentenceTransformer
import pandas as pd
import faiss
import numpy as np

reference_data = pd.read_csv('final_titles.csv')
reference_df = pd.DataFrame(reference_data, columns=['Title', 'Cleaned_Title'])

dirty_data = pd.read_csv('test_data.csv')
dirty_titles = dirty_data['Title'].astype(str).tolist()

encoder = SentenceTransformer("all-MiniLM-L6-v2")
vectors_reference = encoder.encode(reference_df['Title'].tolist())
vector_dimension = vectors_reference.shape[1]
index_reference = faiss.IndexFlatL2(vector_dimension)

vectors_reference = vectors_reference.astype(np.float32)
faiss.normalize_L2(vectors_reference)
index_reference.add(vectors_reference)

vectors_dirty = encoder.encode(dirty_titles)
vectors_dirty = vectors_dirty.astype(np.float32)
faiss.normalize_L2(vectors_dirty)

k = 1
ann_results = []
for vector in vectors_dirty:
    distances, indices = index_reference.search(vector.reshape(1, -1), k=k)
    similarity_scores = 1 - distances
    ann_results.append((indices[0][0], similarity_scores[0][0]))

ann_df = pd.DataFrame(ann_results, columns=['ann', 'similarity_score'])
ann_df['Cleaned_Title'] = ann_df['ann'].apply(lambda idx: reference_df.iloc[idx]['Cleaned_Title'])

merged_df = pd.merge(ann_df, dirty_data, left_index=True, right_index=True)
merged_df[['Title', 'Cleaned_Title', 'similarity_score']]

"""# Cleaning a Single Title with IndexFlatL2"""

from sentence_transformers import SentenceTransformer
import pandas as pd
import faiss
import numpy as np

data = pd.read_csv('final_titles.csv')
df = pd.DataFrame(data, columns=['Title', 'Cleaned_Title'])
title = df['Title'].astype(str).tolist()
encoder = SentenceTransformer("all-MiniLM-L6-v2")
vectors = encoder.encode(title)
vector_dimension = vectors.shape[1]

index = faiss.IndexFlatL2(vector_dimension)

vectors = vectors.astype(np.float32)
faiss.normalize_L2(vectors)

index.add(vectors)

search_text = 'Director of manager,cofounder'

search_vector = encoder.encode([search_text])

search_vector = search_vector.astype(np.float32)
faiss.normalize_L2(search_vector.reshape(1, -1))

k = 5

distances, ann = index.search(search_vector, k=k)

# Convert distances to similarity scores
similarity_scores = 1 - distances

results = pd.DataFrame({'similarity_score': similarity_scores[0], 'ann': ann[0]})

merge = pd.merge(results, df, left_on='ann', right_index=True)

merge.head()

"""# Measuring and Comparing Speed

## Measuring Speed with IndexFlatL2
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# D, I = index.search(search_vector, k)  # search
# print(I)

"""## Speed with IndexIVFFlat (Faster, ~2000 training points )"""

nlist = 50  # how many cells
quantizer = faiss.IndexFlatL2(vector_dimension)
index = faiss.IndexIVFFlat(quantizer, vector_dimension, nlist)
index.train(vectors)  # train the index before adding vectors
index.add(vectors)
index.ntotal

k = 4

# Perform the search
distances, ann = index.search(search_vector, k=k)

# Create a DataFrame with the distances and indices of the nearest neighbors
results = pd.DataFrame({'distances': distances[0], 'ann': ann[0]})

# Merge the results with the original DataFrame to get the titles of the nearest neighbors
merge = pd.merge(results, df, left_on='ann', right_index=True)

# Display the top results
merge.head()

